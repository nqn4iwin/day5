"""
ì±„íŒ… API ë¼ìš°íŠ¸

LangGraph ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì—”ë“œí¬ì¸íŠ¸:
    POST /chat/              - ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ (ì¼ë°˜)
    POST /chat/stream        - SSE ìŠ¤íŠ¸ë¦¬ë°
"""

from typing import AsyncGenerator
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage, AIMessage, AIMessageChunk, BaseMessage
from loguru import logger

from app.schemas.chat import ChatRequest, ChatResponse, StreamEvent
from app.graph import get_lumi_graph

router = APIRouter()

# In-Memory ì„¸ì…˜ ì €ì¥ì†Œ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)
SESSION_STORE: dict[str, list[BaseMessage]] = {}


@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest) -> ChatResponse:
    """
    ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (ì¼ë°˜ - ë¹„ìŠ¤íŠ¸ë¦¬ë°)

    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ LangGraph ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        request: ì±„íŒ… ìš”ì²­ (message, session_id, user_id)

    Returns:
        ChatResponse: ë£¨ë¯¸ì˜ ì‘ë‹µ

    Raises:
        HTTPException: ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜ ì‹œ

    Example:
        ```bash
        curl -X POST "http://localhost:8000/api/v1/chat/" \\
            -H "Content-Type: application/json" \\
            -d '{"message": "ì˜¤ëŠ˜ ë°©ì†¡ ì–¸ì œì•¼?", "session_id": "user123"}'
        ```
    """
    logger.info(f"ğŸ“© ì±„íŒ… ìš”ì²­: session={request.session_id}, message={request.message[:50]}...")

    try:
        # Step 1: LangGraph ê·¸ë˜í”„ ê°€ì ¸ì˜¤ê¸°
        graph = get_lumi_graph()

        # Step 2: ì´ˆê¸° ìƒíƒœ ìƒì„±
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ messagesì— í¬í•¨
        initial_state = {
            "messages": [HumanMessage(content=request.message)],
            "intent": None,
            "retrieved_docs": [],
            "tool_name": None,
            "tool_args": None,
            "tool_result": None,
            "session_id": request.session_id,
            "user_id": request.user_id,
        }

        # Step 3: ê·¸ë˜í”„ ì‹¤í–‰ (ë¹„ë™ê¸°)
        logger.debug("ğŸ”„ LangGraph ì‹¤í–‰ ì‹œì‘")
        final_state = await graph.ainvoke(initial_state)
        logger.debug("âœ… LangGraph ì‹¤í–‰ ì™„ë£Œ")

        # Step 4: ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
        # messages ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ AIMessageê°€ ìµœì¢… ì‘ë‹µ
        messages = final_state["messages"]
        if len(messages) < 2:
            raise ValueError("ì‘ë‹µ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ (AI ì‘ë‹µ)
        ai_response = messages[-1].content
        tool_used = final_state.get("tool_name")

        logger.info(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: tool_used={tool_used}")

        return ChatResponse(
            message=ai_response,
            tool_used=tool_used,
            cached=False,
        )

    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )

# SSE ìŠ¤íŠ¸ë¦¬ë° - Helper í•¨ìˆ˜
async def stream_with_status(
    message: str,
    session_id: str,
    user_id: str | None = None,
) -> AsyncGenerator[tuple[str | None, str | None, str | None, str | None], None]:
    """
    ë…¸ë“œ ìƒíƒœ + í† í° ìŠ¤íŠ¸ë¦¬ë° ê²°í•©

    ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ë©´ì„œ í† í°ë„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    Gradio UIì—ì„œ "ìƒê° ì¤‘...", "Tool ì‹¤í–‰ ì¤‘..." í‘œì‹œì— ì‚¬ìš©ë©ë‹ˆë‹¤.

    í•µì‹¬: stream_mode=["updates", "messages"]
        - updates: ë…¸ë“œ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ â†’ ì§„í–‰ ìƒíƒœ í‘œì‹œ
        - messages: í† í° ë‹¨ìœ„ ì´ë²¤íŠ¸ â†’ ChatGPTì²˜ëŸ¼ ê¸€ì ìŠ¤íŠ¸ë¦¬ë°

    Yields:
        tuple[status, token, final_response, tool_used]:
            - (status, None, None, None): ì§„í–‰ ìƒí™© ë©”ì‹œì§€
            - (None, token, None, None): ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ í† í°
            - (None, None, final_response, tool_used): ìµœì¢… ì‘ë‹µ
    """
    graph = get_lumi_graph()

    # ì„¸ì…˜ì—ì„œ ì´ì „ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    session_id = session_id or "default"
    history = SESSION_STORE.get(session_id, [])
    new_message = HumanMessage(content=message)

    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = {
        "messages": history + [new_message],
        "intent": None,
        "retrieved_docs": [],
        "tool_name": None,
        "tool_args": None,
        "tool_result": None,
        "session_id": session_id,
        "user_id": user_id,
    }

    logger.debug(f"ğŸ“œ [StreamWithStatus] ì„¸ì…˜ íˆìŠ¤í† ë¦¬: {len(history)}ê°œ ë©”ì‹œì§€")

    final_response = ""
    final_tool_name = None
    current_node = None

    # ë…¸ë“œ ì´ë¦„ â†’ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
    node_status = {
        "router": "ğŸ”€ ë£¨ë¯¸ ìƒê° ì¤‘...",
        "rag": "ğŸ“š ì •ë³´ ê²€ìƒ‰ ì¤‘...",
        "tool": "ğŸ”§ ë„êµ¬ ì‹¤í–‰ ì¤‘...",
        "response": "ğŸ’¬ ì‘ë‹µ ì‘ì„± ì¤‘...",
    }

    # í•µì‹¬: ë‘ ëª¨ë“œ ë™ì‹œ ì‚¬ìš©(updates + messages)
    # stream_modeê°€ ë¦¬ìŠ¤íŠ¸ì¼ ë•Œ: (mode_name, event) íŠœí”Œë¡œ ë°˜í™˜ë¨
    async for mode, event in graph.astream(initial_state, stream_mode=["updates", "messages"]):
        # ë…¸ë“œ ìŠ¤íŠ¸ë¦¬ë° (stream_mode="updates") : ë…¸ë“œê°€ ì™„ë£Œë  ë•Œë§ˆë‹¤ ì´ë²¤íŠ¸ ë°œìƒ
        if mode == "updates":
            # event = {"node_name": {ì¶œë ¥ ìƒíƒœ}}
            for node_name, node_output in event.items():
                if node_name != current_node and node_name in node_status:
                    current_node = node_name
                    # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ yield
                    yield (node_status[node_name], None, None, None)
                    logger.debug(f"ğŸ”„ [StreamWithStatus] ë…¸ë“œ ì§„ì…: {node_name}")

                # tool ë…¸ë“œì—ì„œ tool_name ì¶”ì¶œ
                if node_name == "tool" and node_output:
                    final_tool_name = node_output.get("tool_name")

        # í† í° ìŠ¤íŠ¸ë¦¬ë° (stream_mode="messages") : LLMì´ í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ ì´ë²¤íŠ¸ ë°œìƒ
        elif mode == "messages":
            # event = (message, metadata) íŠœí”Œ
            msg, meta = event
            node_name = meta.get("langgraph_node", "")

            # response ë…¸ë“œì˜ í† í°ë§Œ ìŠ¤íŠ¸ë¦¬ë° (router ë…¸ë“œ í† í°ì€ ë¬´ì‹œ)
            if node_name != "response":
                continue

            # AIMessageChunk = í† í° í•˜ë‚˜
            if isinstance(msg, AIMessageChunk):
                token = msg.content or ""
                if token:
                    final_response += token
                    yield (None, token, None, None)

    # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    if final_response:
        if session_id not in SESSION_STORE:
            SESSION_STORE[session_id] = []
        SESSION_STORE[session_id].append(new_message)
        SESSION_STORE[session_id].append(AIMessage(content=final_response))
        logger.debug(f"ğŸ’¾ [StreamWithStatus] ì„¸ì…˜ ì €ì¥: {session_id}")

    # ë§ˆì§€ë§‰ì— ìµœì¢… ì‘ë‹µ yield : status, token, final_response, final_tool_name
    yield (None, None, final_response, final_tool_name)


# SSE ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
@router.post("/stream")
async def chat_stream(request: ChatRequest) -> StreamingResponse:
    """
    SSE ë…¸ë“œ + í† í° ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸

    stream_with_statusë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œ ìƒíƒœ(thinking)ì™€ í† í°ì„ ë™ì‹œì— ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

    SSE ì´ë²¤íŠ¸ íƒ€ì…:
        - thinking: ë…¸ë“œ ì§„í–‰ ìƒí™© ("ğŸ”€ ë£¨ë¯¸ ìƒê° ì¤‘...")
        - token: LLM í† í° (ê¸€ì ë‹¨ìœ„)
        - response: ìµœì¢… ì‘ë‹µ
        - error: ì—ëŸ¬
        - done: ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ

    Example:
        ```bash
        curl -N -X POST "http://localhost:8000/api/v1/chat/stream" \\
            -H "Content-Type: application/json" \\
            -d '{"message": "ì˜¤ëŠ˜ ë°©ì†¡ ì–¸ì œì•¼?", "session_id": "user123"}'
        ```
    """
    logger.info(f"ğŸ“© [Stream] ë…¸ë“œ+í† í° ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­: session={request.session_id}")

    async def generate() -> AsyncGenerator[str, None]:
        """SSE ì´ë²¤íŠ¸ ìƒì„±ê¸° - ë…¸ë“œ ìƒíƒœ + í† í° ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            async for status, token, final, tool_used in stream_with_status(
                request.message,
                request.session_id,
                request.user_id,
            ):
                # ë…¸ë“œ ìƒíƒœ (thinking ì´ë²¤íŠ¸)
                if status:
                    yield StreamEvent(type="thinking", content=status).to_sse()

                # í† í° ìŠ¤íŠ¸ë¦¬ë° (token ì´ë²¤íŠ¸)
                if token:
                    yield StreamEvent(type="token", content=token).to_sse()

                # ìµœì¢… ì‘ë‹µ (response ì´ë²¤íŠ¸)
                if final:
                    yield StreamEvent(
                        type="response", content=final, tool_used=tool_used
                    ).to_sse()

            yield StreamEvent(type="done").to_sse()
            logger.info(f"âœ… [Stream] ì™„ë£Œ: session={request.session_id}")

        except Exception as e:
            logger.error(f"âŒ [Stream] ì˜¤ë¥˜: {e}")
            yield StreamEvent(type="error", error=str(e)).to_sse()
            yield StreamEvent(type="done").to_sse()

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no", 
        },
    )



